{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayer filter\n",
    "\n",
    "To form a color image, we need to collect information at RGB wavelengths for all the pixels or sensors. But this process is expensive both in terms of time and money.\n",
    "\n",
    "So in 1976, Bayer thought of an alternative. Instead of capturing all RGB information at each pixel, Bayer thought of capturing one out of RGB for each pixel. Now, each pixel will contain either R, G or B. To be able to form a color image, he decided 50% pixels be Green and rest equally to Red and Blue (to mimic human eye) and these are arranged in a pattern as shown below\n",
    "![title](./assets/bayer_pattern.png)\n",
    "The pattern can take different forms for example the one shown here is GRBG if the pattern is rotated the pattern will be different but it will preserve the same colors ration of Green 50%, Red 25% and Blue 25 %\n",
    "\n",
    "An Example of bayer image is shown in the following image\n",
    "![title](./assets/image_bayer.png)\n",
    "After interpolation the image to RGB image\n",
    "![title](./assets/image_real.png)\n",
    "## Why Green is 50 %\n",
    "There are as many green pixels as there are blue and red combined. This is because the human eye is not equally sensitive to all three colors. It's necessary to include more information from the green pixels in order to create an image that the eye will perceive as a \"true color.\"\n",
    "\n",
    "The gray scale or intensity of the color is computed as following:\n",
    "$$I = 0.299R + 0.587G + 0.114B$$\n",
    "## Generating RGB image\n",
    "\"Demosaicing\" is the process of translating this Bayer array of primary colors into a final image which contains full color information at each pixel.\n",
    "\n",
    "Check https://www.cambridgeincolour.com/tutorials/camera-sensors.htm for more explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (600, 408)\n",
      "image range:[2, 255] and dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./assets/my_image_bayer.png', cv2.IMREAD_GRAYSCALE)\n",
    "print('image shape', img.shape)\n",
    "print('image range:[{}, {}] and dtype: {}'.format(img.min(), img.max(), img.dtype))\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(figure_name: str, img: np.ndarray):\n",
    "    cv2.imshow(figure_name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert the bayer image into RGB image using `cv2.cvtColor` function, for docs check https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html\n",
    "\n",
    "Note the enum used for conversion `COLOR_BAYER_GR2BGR`. Since bayer pattern can take many forms, RGGB pattern is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (600, 408)\n",
      "image range:[2, 255] and dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "###      MY CODE   ###\n",
    "#solution :\n",
    "img = cv2.imread('./assets/my_image_bayer.png', cv2.IMREAD_GRAYSCALE)\n",
    "img_after_conversion=cv2.cvtColor(img,cv2.COLOR_BAYER_GR2BGR)\n",
    "print('image shape', img.shape)\n",
    "print('image range:[{}, {}] and dtype: {}'.format(img.min(), img.max(), img.dtype))\n",
    "cv2.imshow('img_after_conversion', img_after_conversion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 319 is out of bounds for axis 0 with size 318",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-676d22e55ef8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmy_rgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmy_rgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmy_rgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 319 is out of bounds for axis 0 with size 318"
     ]
    }
   ],
   "source": [
    "##Please,note there is a problem in this code \n",
    "\n",
    "img = cv2.imread('./assets/rgb_color_space.png',0)\n",
    "i,j= img.shape \n",
    "\n",
    "my_rgb[i//2, j//2, 0] = img[i+1, j+1]        \n",
    "my_rgb[i//2, j//2, 1] = ((int(img[i+1, j]) + int(img[i, j+1]))/2)\n",
    "my_rgb[i//2, j//2, 2] = img[i, j]\n",
    "visualize_image('my_rgb', my_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_rgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c7ff6c725bb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_rgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'my_rgb' is not defined"
     ]
    }
   ],
   "source": [
    "my_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.cvtColor(img, cv2.COLOR_BAYER_BG2BGR)\n",
    "visualize_image('rgb', rgb)\n",
    "# TODO: Implement your own bayer image to RGB function\n",
    "# TODO: Implement function that convert RGB image to bayer image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MY CODE ###\n",
    "#1-\n",
    "#img = cv2.imread('./assets/my_image_bayer.png', cv2.IMREAD_GRAYSCALE)\n",
    "#rgb_2=img*rgb\n",
    "\n",
    "#----------\n",
    "#2-\n",
    "\"\"\"\n",
    "def rgb_brayer(rgb_img):\n",
    "    bayer_img = cv2.cvtColor(rgb_img, cv2.COLOR_BG2BGR_BAYER)\n",
    "    visualize_image('bayer_imge', bayer_img)\n",
    "    \n",
    "    return bayer_img\n",
    "\n",
    "rgb_img = cv2.imread('./assets/rgb_img.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color spaces\n",
    "We will now explore the difference and the need for multiple color spaces. For an example we will try to segment the following images of rubik's cube face.\n",
    "![title](./assets/rubik_dark.png)\n",
    "![title](./assets/rubik_light.png)\n",
    "\n",
    "Both images are of the same face but with different light conditions\n",
    "\n",
    "## RGB\n",
    "![title](./assets/rgb_color_space.png)\n",
    "The downside of RGB is:\n",
    "* mixing of chrominance ( Color related information ) and luminance ( Intensity related information ) data.\n",
    "* significant perceptual non-uniformity. (check the difference between the white and blue colors through the blue channel)\n",
    "\n",
    "## YCrCb\n",
    "The YCrCb color space is derived from the RGB color space and has the following three compoenents.\n",
    "* Y: The Luminance  or luma(intensity)\n",
    "* Cr: How far the red component from the Luminance\n",
    "* Cb: How far the blue component from the Luminance \n",
    "![title](./assets/ycrcb.png)\n",
    "\n",
    "YCrCb separates the luminance and chrominance components into different channels helping in understanding the effect of different lighting conditions\n",
    "![title](./assets/ycrcb_color_space.png)\n",
    "\n",
    "## HSV (HSI)\n",
    "HSV color space has the following three components:\n",
    "* H: Hue, the dominant wavelength\n",
    "* S: Saturation, purity of the color \n",
    "* V: Value (intensity)\n",
    "For more details about HSV check https://www.lifewire.com/what-is-hsv-in-design-1078068\n",
    "![title](./assets/hsv.png)\n",
    "\n",
    "Best thing is that it uses only one channel to describe color (H), making it very intuitive to specify color.\n",
    "![title](./assets/hsv_color_space.png)\n",
    "\n",
    "**Watch out!** Hue's value doesn't represent a color on its own!. it represents an angle on a circle as shown in the previous figure. For example hue values as degrees looks as following:\n",
    "* Red falls between 0 and 60 degrees.\n",
    "* Yellow falls between 61 and 120 degrees.\n",
    "* Green falls between 121-180 degrees.\n",
    "* Cyan falls between 181-240 degrees.\n",
    "* Blue falls between 241-300 degrees.\n",
    "* Magenta falls between 301-360 degrees\n",
    "\n",
    "### How to represent white then ?!!\n",
    "White is not a color or if we are using H(Hue) terminology, white is not a wave length so how it is represented?\n",
    "\n",
    "From the figure above we can see that White can be represented by any Hue! but only when saturation is 0. Then how to determine how white the color is? For example if the pixel `P1` has the values `(255, 255, 255)` in RGB and `P2` has `(250, 250, 250)` how can we know the difference using Hue and Saturation?\n",
    "\n",
    "The answer is that we can't! We need to use the Value channel for this! `P1` in HSV has the value `(0, 0, 255)` and `P2` has `(0, 0, 250)`.\n",
    "\n",
    "The same idea can be used for black. Some variations of HSV help with this problem for example HSL \n",
    "\n",
    "Check the following tutorial for more explanation https://www.learnopencv.com/color-spaces-in-opencv-cpp-python/\n",
    "If you want to see more color spaces check https://www.w3schools.com/colors/default.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_img = cv2.imread('./assets/rubik_light.png')\n",
    "dark_img = cv2.imread('./assets/rubik_dark.png')\n",
    "visualize_image('light_img', light_img)\n",
    "visualize_image('light_img', dark_img)\n",
    "\n",
    "ycrcb_light = cv2.cvtColor(light_img, cv2.COLOR_BGR2YCrCb)\n",
    "ycrcb_dark = cv2.cvtColor(dark_img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "hsv_light = cv2.cvtColor(light_img, cv2.COLOR_BGR2HSV)\n",
    "hsv_dark = cv2.cvtColor(dark_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "visualize_image('img', hsv_dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
